{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f7773-42c6-4ff7-bb20-1f1eb21a9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score, roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Import PyCaret\n",
    "from pycaret.classification import setup as setup_classification, compare_models as compare_models_classification\n",
    "from pycaret.regression import setup as setup_regression, compare_models as compare_models_regression\n",
    "\n",
    "\n",
    "def perform_eda(data):\n",
    "    st.header(\"Exploratory Data Analysis (EDA):-\")\n",
    "    st.subheader(\"Data Types\")\n",
    "    st.write(data.dtypes)\n",
    "\n",
    "    analyze_data = st.checkbox(\"Perform EDA?\")\n",
    "    if analyze_data:\n",
    "        visualiz_columns = st.multiselect(\"Select the columns for visualization:\", options=data.columns)\n",
    "        if visualiz_columns:\n",
    "            numeric_columns = data[visualiz_columns].select_dtypes(include=['number']).columns\n",
    "            st.subheader(\"Histograms\")\n",
    "            for column in numeric_columns:\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                sns.histplot(data=data, x=column, kde=True)\n",
    "                plt.title(f\"Histogram For numerical data - {column}\")\n",
    "                plt.xlabel(column)\n",
    "                plt.ylabel(\"Frequency of values\")\n",
    "                plt.show()\n",
    "                st.pyplot()\n",
    "        st.subheader(\"Boxplot\")\n",
    "        for column in numeric_columns:\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            sns.boxplot(data=data, y=column)\n",
    "            plt.title(f\"Box Plot For numerical data - {column}\")\n",
    "            plt.ylabel(column)\n",
    "            plt.show()\n",
    "            st.pyplot()\n",
    "        st.subheader(\"Scatterplot\")\n",
    "        if len(numeric_columns) >= 2:\n",
    "            for i in range(len(numeric_columns)):\n",
    "                for j in range(i + 1, len(numeric_columns)):\n",
    "                    plt.figure(figsize=(8, 6))\n",
    "                    sns.scatterplot(data=data, x=numeric_columns[i], y=numeric_columns[j])\n",
    "                    plt.title(f\"Scatter Plot VS {numeric_columns[i]} and {numeric_columns[j]}\")\n",
    "                    plt.xlabel(numeric_columns[i])\n",
    "                    plt.ylabel(numeric_columns[j])\n",
    "                    plt.show()\n",
    "                    st.pyplot()\n",
    "        st.subheader(\"Correlation Matrix\")\n",
    "        if len(numeric_columns) >= 2:\n",
    "            correlation_matrix = data[visualiz_columns].corr()\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "            plt.title(\"Heatmap For correlation coefficients between numerical features\")\n",
    "            plt.show()\n",
    "            st.pyplot()\n",
    "\n",
    "\n",
    "def encode_categorical(data):\n",
    "    categorical_features = data.select_dtypes(include=['object']).columns\n",
    "    encoding_method = st.radio(\"Select encoding method for categorical data:\", (\"Label Encoding\", \"One-Hot Encoding\"))\n",
    "    if encoding_method == \"Label Encoding\":\n",
    "        label_encoders = {}\n",
    "        for col in categorical_features:\n",
    "            label_encoders[col] = LabelEncoder()\n",
    "            data[col] = label_encoders[col].fit_transform(data[col])\n",
    "    elif encoding_method == \"One-Hot Encoding\":\n",
    "        data = pd.get_dummies(data, columns=categorical_features)\n",
    "    return data\n",
    "\n",
    "\n",
    "def drop_duplicates(data):\n",
    "    st.header(\"Select Drop Duplicate Rows?\")\n",
    "    drop_duplicates_option = st.checkbox(\"Drop duplicate\", key=\"drop_duplicates_checkbox\")\n",
    "\n",
    "    if drop_duplicates_option:\n",
    "        data.drop_duplicates(inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def choose_variables(data):\n",
    "    st.header(\"Choose X and Y variables\")\n",
    "    X_variables = st.multiselect(\"Select independent variables (X):\", options=data.columns)\n",
    "    Y_variable = st.selectbox(\"Select dependent variable (Y):\", options=data.columns)\n",
    "    return X_variables, Y_variable\n",
    "\n",
    "\n",
    "def normalize_features(X, scaler_type='standard'):\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "    X_normalized = scaler.fit_transform(X)\n",
    "    return X_normalized\n",
    "\n",
    "\n",
    "def main():\n",
    "    with st.sidebar:\n",
    "        st.header(\"Steps to prediction accuracy:-\")\n",
    "        st.text(\"1- Upload CSV or Excel file \")\n",
    "        st.text(\"2- Choose target feature\")\n",
    "        st.text(\"3- Perform some EDA\")\n",
    "        st.text(\"4- Handle missing values\")\n",
    "        st.text(\"5- Drop duplicates\")\n",
    "        st.text(\"6- Choose X and Y \")\n",
    "        st.text(\"7- Split (X, Y) for train/test\")\n",
    "        st.text(\"8- Encode categorical data \")\n",
    "        st.text(\"9- Normalize data\")\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    target = \"\"\n",
    "\n",
    "    dataset = st.file_uploader(\"Upload CSV or Excel file\", type=['csv', 'xlsx'])\n",
    "    if dataset is not None:\n",
    "        if \"csv\" in dataset.name:\n",
    "            data = pd.read_csv(dataset)\n",
    "        elif \"xlsx\" in dataset.name:\n",
    "            data = pd.read_excel(dataset)\n",
    "        st.write(data.head())\n",
    "        st.write(data.shape)\n",
    "\n",
    "        target = st.selectbox(\"Choose the target variable:\", options=data.columns)\n",
    "\n",
    "        perform_eda(data)\n",
    "\n",
    "        data = encode_categorical(data)\n",
    "\n",
    "        drop_duplicates(data)\n",
    "\n",
    "        select_columns = st.multiselect(\"Select features to remove from the dataframe:\", options=data.columns)\n",
    "        if select_columns:\n",
    "            data.drop(select_columns, axis=1, inplace=True)\n",
    "\n",
    "        X_variables, Y_variable = choose_variables(data)\n",
    "\n",
    "        numerical_features = data.select_dtypes(['int64', 'float64']).columns\n",
    "        categorical_feature = data.select_dtypes(['object']).columns\n",
    "        missing_value_num = st.radio(\"Set missing value for numerical value\", [\"mean\", \"median\"])\n",
    "        missing_value_cat = st.radio(\"Set missing value for categorical value\", ['most frequent', 'additional class'])\n",
    "\n",
    "        # Handle missing values for numerical columns\n",
    "        for col in numerical_features:\n",
    "            data[col] = SimpleImputer(strategy=missing_value_num, missing_values=np.nan).fit_transform(data[col].values.reshape(-1, 1))\n",
    "\n",
    "        # Handle missing values for categorical columns\n",
    "        for col in categorical_feature:\n",
    "            if missing_value_cat == 'most frequent':\n",
    "                data[col] = SimpleImputer(strategy='most_frequent', missing_values=np.nan).fit_transform(data[col].values.reshape(-1, 1))\n",
    "            elif missing_value_cat == 'additional class':\n",
    "                data[col] = data[col].fillna('Missing')\n",
    "\n",
    "        st.subheader(\"Data Types\")\n",
    "        st.write(data.dtypes)\n",
    "\n",
    "        # Detect task type based on the target variable\n",
    "        if pd.api.types.is_numeric_dtype(data[target]):\n",
    "            task_type = \"Regression\"\n",
    "        else:\n",
    "            task_type = \"Classification\"\n",
    "\n",
    "        st.write(f\"Detected Task: {task_type}\")\n",
    "\n",
    "        # Use PyCaret to train models\n",
    "        if task_type == \"Classification\":\n",
    "            st.write(\"Running PyCaret Classification\")\n",
    "            clf_setup = setup_classification(data=data, target=target, silent=True, session_id=42)\n",
    "            best_model = compare_models_classification()\n",
    "            st.write(\"Best Classification Model:\")\n",
    "            st.write(best_model)\n",
    "\n",
    "        elif task_type == \"Regression\":\n",
    "            st.write(\"Running PyCaret Regression\")\n",
    "            reg_setup = setup_regression(data=data, target=target, silent=True, session_id=42)\n",
    "            best_model = compare_models_regression()\n",
    "            st.write(\"Best Regression Model:\")\n",
    "            st.write(best_model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
